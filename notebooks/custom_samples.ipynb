{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed60b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve,roc_auc_score, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score , precision_score , recall_score ,  f1_score , precision_recall_curve , roc_auc_score \n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939105e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "175744c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27f1a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb9257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31036b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Class'])\n",
    "y = data[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d41072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,train_size=.75,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39c95a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([X_train,y_train],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb4519",
   "metadata": {},
   "source": [
    "i have to get the balanced data from the train only :\n",
    "- if i get frauds and non_frauds from the whole data then test on the ( X_test ) this will cause a data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78e552a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Class\n",
       " 0    212433\n",
       " Name: count, dtype: int64,\n",
       " Class\n",
       " 1    361\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nor_frauds = train[train['Class'] == 0]   # trian not data\n",
    "frauds = train[train['Class'] == 1]\n",
    "nor_frauds['Class'].value_counts(),frauds['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b43ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    180500\n",
       "1       361\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df = pd.concat([ frauds , nor_frauds.sample(500*len(frauds) ,random_state=42)],axis=0)\n",
    "balanced_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1804f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balanced = balanced_df.drop(columns=['Class'])\n",
    "y_balanced = balanced_df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78335950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bakanced_train ,x_bakanced_test , y_bakanced_train,y_bakanced_test = train_test_split(x_balanced,y_balanced,train_size=.80,stratify=y_balanced,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "690a30ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB results : \n",
      "\n",
      "accuracy_score is : 0.9992950995319461 \n",
      "precision_score is : 0.7627118644067796\n",
      "recall_score is : 0.8035714285714286\n",
      "f1_score is : 0.782608695652174\n",
      "best threshold for max f1_score : \n",
      "\n",
      "best Threshold: 0.9010685\n",
      "Precision (custom threshold): 0.925531914893617\n",
      "Recall (custom threshold): 0.7767857142857143\n",
      "F1-score (custom threshold): 0.8446601941747572\n",
      "best threshold for max recall : \n",
      "\n",
      "best Threshold: 0.867203\n",
      "Precision (custom threshold): 0.90625\n",
      "Recall (custom threshold): 0.7767857142857143\n",
      "F1-score (custom threshold): 0.8365384615384616\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(scale_pos_weight=14, random_state=42)\n",
    "xgb_model.fit(x_bakanced_train, y_bakanced_train)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_proba = xgb_model.predict_proba(X_test)\n",
    "print(\"XGB results : \\n\")\n",
    "print(f\"accuracy_score is : {accuracy_score(y_test, y_pred)} \")\n",
    "print(f\"precision_score is : {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall_score is : {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score is : {f1_score(y_test, y_pred)}\")\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "# حساب F1 لكل threshold\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "# أفضل threshold\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9e0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(x_bakanced_train,y_bakanced_train)\n",
    "y_predicted = model.predict(x_bakanced_test)\n",
    "\n",
    "score_acc = accuracy_score(y_bakanced_test , y_predicted)\n",
    "score_precision = precision_score(y_bakanced_test , y_predicted)\n",
    "score_recall = recall_score(y_bakanced_test , y_predicted)\n",
    "score_f1 = f1_score(y_bakanced_test , y_predicted)\n",
    "\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Accuracy  : {score_acc:.4f}\")\n",
    "print(f\"Precision : {score_precision:.4f}\")\n",
    "print(f\"Recall    : {score_recall:.4f}\")\n",
    "print(f\"F1 Score  : {score_f1:.4f}\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "y_predicted = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)\n",
    "score_acc = accuracy_score(y_test , y_predicted)\n",
    "score_precision = precision_score(y_test , y_predicted)\n",
    "score_recall = recall_score(y_test , y_predicted)\n",
    "score_f1 = f1_score(y_test , y_predicted)\n",
    "print('real test results : ')\n",
    "print(f\"Model: {model.__class__.__name__}\")\n",
    "print(f\"Accuracy  : {score_acc:.4f}\")\n",
    "print(f\"Precision : {score_precision:.4f}\")\n",
    "print(f\"Recall    : {score_recall:.4f}\")\n",
    "print(f\"F1 Score  : {score_f1:.4f}\")\n",
    "print(\"*\"*30)\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc481a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is : 0.9995241955380115 \n",
      "precision_score is : 0.8987341772151899\n",
      "recall_score is : 0.7888888888888889\n",
      "f1_score is : 0.8402366863905325\n",
      "The ROC score is : 0.9454606161159748\n",
      "******************************\n",
      "best threshold for max f1_score : \n",
      "\n",
      "best Threshold: 0.535\n",
      "Precision (custom threshold): 0.9102564102564102\n",
      "Recall (custom threshold): 0.7888888888888889\n",
      "F1-score (custom threshold): 0.8452380952380952\n",
      "best threshold for max recall : \n",
      "\n",
      "best Threshold: 0.535\n",
      "Precision (custom threshold): 0.9102564102564102\n",
      "Recall (custom threshold): 0.7888888888888889\n",
      "F1-score (custom threshold): 0.8452380952380952\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 200 , random_state = 42 , n_jobs = -1)\n",
    "random_forest.fit(x_bakanced_train , y_bakanced_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "y_proba = random_forest.predict_proba(X_test)\n",
    "print(f\"accuracy_score is : {accuracy_score(y_test, y_pred)} \")\n",
    "print(f\"precision_score is : {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall_score is : {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score is : {f1_score(y_test, y_pred)}\")\n",
    "print(f\"The ROC score is : {roc_auc_score(y_test , y_proba[:,1])}\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15aedb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ec31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTETomek(sampling_strategy=0.5, random_state=42)\n",
    "X_train_ns, y_train_ns = os.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa8612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is : 0.9995770597191677 \n",
      "precision_score is : 0.9183673469387755\n",
      "recall_score is : 0.8035714285714286\n",
      "f1_score is : 0.8571428571428571\n",
      "The ROC score is : 0.9725194280267884\n",
      "******************************\n",
      "best threshold for max f1_score : \n",
      "\n",
      "best Threshold: 0.54\n",
      "Precision (custom threshold): 0.9278350515463918\n",
      "Recall (custom threshold): 0.8035714285714286\n",
      "F1-score (custom threshold): 0.861244019138756\n",
      "best threshold for max recall : \n",
      "\n",
      "best Threshold: 0.435\n",
      "Precision (custom threshold): 0.900990099009901\n",
      "Recall (custom threshold): 0.8125\n",
      "F1-score (custom threshold): 0.8544600938967136\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 200 , random_state = 42 , n_jobs = -1)\n",
    "random_forest.fit(X_train_ns,y_train_ns)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "y_proba = random_forest.predict_proba(X_test)\n",
    "print(f\"accuracy_score is : {accuracy_score(y_test, y_pred)} \")\n",
    "print(f\"precision_score is : {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall_score is : {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score is : {f1_score(y_test, y_pred)}\")\n",
    "print(f\"The ROC score is : {roc_auc_score(y_test , y_proba[:,1])}\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6949105",
   "metadata": {},
   "source": [
    "Best results till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18c662d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTETomek(sampling_strategy=0.75, random_state=42)\n",
    "X_train_ns, y_train_ns = os.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66ead815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is : 0.9995629617098066 \n",
      "precision_score is : 0.9090909090909091\n",
      "recall_score is : 0.8035714285714286\n",
      "f1_score is : 0.8530805687203792\n",
      "The ROC score is : 0.9770366648848186\n",
      "******************************\n",
      "best threshold for max f1_score : \n",
      "\n",
      "best Threshold: 0.42\n",
      "Precision (custom threshold): 0.9108910891089109\n",
      "Recall (custom threshold): 0.8214285714285714\n",
      "F1-score (custom threshold): 0.863849765258216\n",
      "best threshold for max recall : \n",
      "\n",
      "best Threshold: 0.395\n",
      "Precision (custom threshold): 0.9019607843137255\n",
      "Recall (custom threshold): 0.8214285714285714\n",
      "F1-score (custom threshold): 0.8598130841121495\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 200 , random_state = 42 , n_jobs = -1)\n",
    "random_forest.fit(X_train_ns,y_train_ns)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "y_proba = random_forest.predict_proba(X_test)\n",
    "print(f\"accuracy_score is : {accuracy_score(y_test, y_pred)} \")\n",
    "print(f\"precision_score is : {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall_score is : {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score is : {f1_score(y_test, y_pred)}\")\n",
    "print(f\"The ROC score is : {roc_auc_score(y_test , y_proba[:,1])}\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec0eabc",
   "metadata": {},
   "source": [
    "best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f61707ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTETomek(sampling_strategy=0.5, random_state=42)\n",
    "X_balanced_train_ns, y_balanced_train_ns = os.fit_resample(x_bakanced_train, y_bakanced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8936769b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    180500\n",
       "1       361\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "balanced_df = pd.concat([ frauds , nor_frauds.sample(500*len(frauds) ,random_state=42)],axis=0)\n",
    "balanced_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62c193",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balanced = balanced_df.drop(columns=['Class'])\n",
    "y_balanced = balanced_df[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79402568",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bakanced_train ,x_bakanced_test , y_bakanced_train,y_bakanced_test = train_test_split(x_balanced,y_balanced,train_size=.80,stratify=y_balanced,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39f34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os = SMOTETomek(sampling_strategy=0.5, random_state=42)\n",
    "X_balanced_train_ns, y_balanced_train_ns = os.fit_resample(x_bakanced_train, y_bakanced_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4975a86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is : 0.9995206676817233 \n",
      "precision_score is : 0.89\n",
      "recall_score is : 0.7946428571428571\n",
      "f1_score is : 0.839622641509434\n",
      "The ROC score is : 0.9641654395449227\n",
      "******************************\n",
      "best threshold for max f1_score : \n",
      "\n",
      "best Threshold: 0.68\n",
      "Precision (custom threshold): 0.956989247311828\n",
      "Recall (custom threshold): 0.7946428571428571\n",
      "F1-score (custom threshold): 0.8682926829268293\n",
      "best threshold for max recall : \n",
      "\n",
      "best Threshold: 0.555\n",
      "Precision (custom threshold): 0.9081632653061225\n",
      "Recall (custom threshold): 0.7946428571428571\n",
      "F1-score (custom threshold): 0.8476190476190476\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 200 , random_state = 42 , n_jobs = -1)\n",
    "random_forest.fit(X_balanced_train_ns,y_balanced_train_ns)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "y_proba = random_forest.predict_proba(X_test)\n",
    "print(f\"accuracy_score is : {accuracy_score(y_test, y_pred)} \")\n",
    "print(f\"precision_score is : {precision_score(y_test, y_pred)}\")\n",
    "print(f\"recall_score is : {recall_score(y_test, y_pred)}\")\n",
    "print(f\"f1_score is : {f1_score(y_test, y_pred)}\")\n",
    "print(f\"The ROC score is : {roc_auc_score(y_test , y_proba[:,1])}\")\n",
    "\n",
    "print(\"*\" * 30)\n",
    "\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "\n",
    "print(\"best threshold for max f1_score : \\n\")\n",
    "\n",
    "\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "best_threshold = thresholds[f1_scores.argmax()]\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n",
    "\n",
    "print(\"best threshold for max recall : \\n\")\n",
    "min_precision = .9\n",
    "valid_idx = np.where(precisions[:-1] >= min_precision)[0]\n",
    "best_threshold = thresholds[valid_idx][recalls[valid_idx].argmax()]\n",
    "\n",
    "print(\"best Threshold:\", best_threshold)\n",
    "y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "print(f\"Precision (custom threshold): {precision_score(y_test, y_pred_custom)}\")\n",
    "print(f\"Recall (custom threshold): {recall_score(y_test, y_pred_custom)}\")\n",
    "print(f\"F1-score (custom threshold): {f1_score(y_test, y_pred_custom)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114b254",
   "metadata": {},
   "source": [
    "best results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2cbd918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cac108cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.99954182 0.99964755 0.99943607 0.99968279 0.99948894]\n",
      "Mean accuracy: 0.9995594341640042\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5 folds\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')\n",
    "print(\"Scores for each fold:\", scores)\n",
    "print(\"Mean accuracy:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d162a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "accuracy_score: 0.9995\n",
      "precision_score: 0.9211\n",
      "recall_score: 0.7778\n",
      "f1_score: 0.8434\n",
      "roc_auc_score: 0.9692\n",
      "Best threshold (max F1): 0.6400\n",
      "Custom Precision: 0.9589\n",
      "Custom Recall: 0.7778\n",
      "Custom F1: 0.8589\n",
      "\n",
      "=== Fold 2 ===\n",
      "accuracy_score: 0.9996\n",
      "precision_score: 0.8537\n",
      "recall_score: 0.8434\n",
      "f1_score: 0.8485\n",
      "roc_auc_score: 0.9900\n",
      "Best threshold (max F1): 0.7850\n",
      "Custom Precision: 0.9200\n",
      "Custom Recall: 0.8313\n",
      "Custom F1: 0.8734\n",
      "\n",
      "=== Fold 3 ===\n",
      "accuracy_score: 0.9994\n",
      "precision_score: 0.8969\n",
      "recall_score: 0.7699\n",
      "f1_score: 0.8286\n",
      "roc_auc_score: 0.9591\n",
      "Best threshold (max F1): 0.6900\n",
      "Custom Precision: 0.9247\n",
      "Custom Recall: 0.7611\n",
      "Custom F1: 0.8350\n",
      "\n",
      "=== Fold 4 ===\n",
      "accuracy_score: 0.9996\n",
      "precision_score: 0.8587\n",
      "recall_score: 0.8681\n",
      "f1_score: 0.8634\n",
      "roc_auc_score: 0.9768\n",
      "Best threshold (max F1): 0.8550\n",
      "Custom Precision: 0.9383\n",
      "Custom Recall: 0.8352\n",
      "Custom F1: 0.8837\n",
      "\n",
      "=== Fold 5 ===\n",
      "accuracy_score: 0.9995\n",
      "precision_score: 0.8526\n",
      "recall_score: 0.8438\n",
      "f1_score: 0.8482\n",
      "roc_auc_score: 0.9839\n",
      "Best threshold (max F1): 0.6700\n",
      "Custom Precision: 0.8889\n",
      "Custom Recall: 0.8333\n",
      "Custom F1: 0.8602\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]   # <--- FIXED\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]   # <--- FIXED\n",
    "\n",
    "    # Resample ONLY training data\n",
    "    smt = SMOTETomek(random_state=42)\n",
    "    X_train_res, y_train_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Fit Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    random_forest.fit(X_train_res, y_train_res)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = random_forest.predict(X_test)\n",
    "    y_proba = random_forest.predict_proba(X_test)\n",
    "\n",
    "    # Basic metrics\n",
    "    print(f\"\\n=== Fold {fold} ===\")\n",
    "    print(f\"accuracy_score: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"precision_score: {precision_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"recall_score: {recall_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"f1_score: {f1_score(y_test, y_pred):.4f}\")\n",
    "    print(f\"roc_auc_score: {roc_auc_score(y_test, y_proba[:,1]):.4f}\")\n",
    "\n",
    "    # Precision-recall curve\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_test, y_proba[:,1])\n",
    "    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)\n",
    "\n",
    "    # Best threshold (max F1)\n",
    "    best_threshold = thresholds[f1_scores.argmax()]\n",
    "    y_pred_custom = (y_proba[:,1] >= best_threshold).astype(int)\n",
    "    print(f\"Best threshold (max F1): {best_threshold:.4f}\")\n",
    "    print(f\"Custom Precision: {precision_score(y_test, y_pred_custom):.4f}\")\n",
    "    print(f\"Custom Recall: {recall_score(y_test, y_pred_custom):.4f}\")\n",
    "    print(f\"Custom F1: {f1_score(y_test, y_pred_custom):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c06cbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cross-validation Results (Mean ± Std) ===\n",
      "Accuracy: 0.9995 ± 0.0001\n",
      "Precision: 0.8766 ± 0.0276\n",
      "Recall: 0.8206 ± 0.0393\n",
      "F1 Score: 0.8464 ± 0.0112\n",
      "ROC-AUC: 0.9758 ± 0.0109\n",
      "--- Custom Threshold ---\n",
      "Precision: 0.9262 ± 0.0230\n",
      "Recall: 0.8077 ± 0.0317\n",
      "F1 Score: 0.8622 ± 0.0164\n"
     ]
    }
   ],
   "source": [
    "# Store your fold results in lists\n",
    "accuracy = [0.9995, 0.9996, 0.9994, 0.9996, 0.9995]\n",
    "precision = [0.9211, 0.8537, 0.8969, 0.8587, 0.8526]\n",
    "recall = [0.7778, 0.8434, 0.7699, 0.8681, 0.8438]\n",
    "f1 = [0.8434, 0.8485, 0.8286, 0.8634, 0.8482]\n",
    "roc_auc = [0.9692, 0.9900, 0.9591, 0.9768, 0.9839]\n",
    "\n",
    "# Custom threshold metrics\n",
    "custom_precision = [0.9589, 0.9200, 0.9247, 0.9383, 0.8889]\n",
    "custom_recall = [0.7778, 0.8313, 0.7611, 0.8352, 0.8333]\n",
    "custom_f1 = [0.8589, 0.8734, 0.8350, 0.8837, 0.8602]\n",
    "\n",
    "def summarize(name, values):\n",
    "    print(f\"{name}: {np.mean(values):.4f} ± {np.std(values):.4f}\")\n",
    "\n",
    "print(\"=== Cross-validation Results (Mean ± Std) ===\")\n",
    "summarize(\"Accuracy\", accuracy)\n",
    "summarize(\"Precision\", precision)\n",
    "summarize(\"Recall\", recall)\n",
    "summarize(\"F1 Score\", f1)\n",
    "summarize(\"ROC-AUC\", roc_auc)\n",
    "print(\"--- Custom Threshold ---\")\n",
    "summarize(\"Precision\", custom_precision)\n",
    "summarize(\"Recall\", custom_recall)\n",
    "summarize(\"F1 Score\", custom_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
